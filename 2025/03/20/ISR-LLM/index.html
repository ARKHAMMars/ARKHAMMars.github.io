<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning笔记 | CMY's Blog</title><meta name="author" content="Mengyang Cheng"><meta name="copyright" content="Mengyang Cheng"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="论文梳理目的构造一个通过迭代自我完善过程来改进基于大语言模型的规划的全新框架。 Related WorkLong-Horizon Sequential Task Planning使用基于搜索或基于采样的算法来找到可行的计划然而，这些方法依赖于对规划领域预先确定的符号和逻辑表示，这通常需要高水平的专业知识来制定 TAMP将离散空间中的高级任务规划和连续空间中的低级机器人运动规划结合成一个分层规划框架">
<meta property="og:type" content="article">
<meta property="og:title" content="ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning笔记">
<meta property="og:url" content="https://arkham-three.vercel.app/2025/03/20/ISR-LLM/index.html">
<meta property="og:site_name" content="CMY&#39;s Blog">
<meta property="og:description" content="论文梳理目的构造一个通过迭代自我完善过程来改进基于大语言模型的规划的全新框架。 Related WorkLong-Horizon Sequential Task Planning使用基于搜索或基于采样的算法来找到可行的计划然而，这些方法依赖于对规划领域预先确定的符号和逻辑表示，这通常需要高水平的专业知识来制定 TAMP将离散空间中的高级任务规划和连续空间中的低级机器人运动规划结合成一个分层规划框架">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://arkham-three.vercel.app/img/butterfly-icon.png">
<meta property="article:published_time" content="2025-03-20T08:59:01.021Z">
<meta property="article:modified_time" content="2025-03-21T14:35:48.675Z">
<meta property="article:author" content="Mengyang Cheng">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://arkham-three.vercel.app/img/butterfly-icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning笔记",
  "url": "https://arkham-three.vercel.app/2025/03/20/ISR-LLM/",
  "image": "https://arkham-three.vercel.app/img/butterfly-icon.png",
  "datePublished": "2025-03-20T08:59:01.021Z",
  "dateModified": "2025-03-21T14:35:48.675Z",
  "author": [
    {
      "@type": "Person",
      "name": "Mengyang Cheng",
      "url": "https://arkham-three.vercel.app/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://arkham-three.vercel.app/2025/03/20/ISR-LLM/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning笔记',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/custom.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">CMY's Blog</span></a><a class="nav-page-title" href="/"><span class="site-name">ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning笔记</span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-03-20T08:59:01.021Z" title="Created 2025-03-20 16:59:01">2025-03-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-03-21T14:35:48.675Z" title="Updated 2025-03-21 22:35:48">2025-03-21</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="论文梳理"><a href="#论文梳理" class="headerlink" title="论文梳理"></a>论文梳理</h1><h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>构造一个通过迭代自我完善过程来改进基于大语言模型的规划的全新框架。</p>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Long-Horizon-Sequential-Task-Planning"><a href="#Long-Horizon-Sequential-Task-Planning" class="headerlink" title="Long-Horizon Sequential Task Planning"></a>Long-Horizon Sequential Task Planning</h3><h4 id="使用基于搜索或基于采样的算法来找到可行的计划"><a href="#使用基于搜索或基于采样的算法来找到可行的计划" class="headerlink" title="使用基于搜索或基于采样的算法来找到可行的计划"></a>使用基于搜索或基于采样的算法来找到可行的计划</h4><p>然而，这些方法依赖于对规划领域预先确定的符号和逻辑表示，这通常需要高水平的专业知识来制定</p>
<h4 id="TAMP"><a href="#TAMP" class="headerlink" title="TAMP"></a>TAMP</h4><p>将离散空间中的高级任务规划和连续空间中的低级机器人运动规划结合成一个分层规划框架。在任务与运动规划中，关注点不仅限于单纯的任务规划，还包括所确定行动的可执行性</p>
<h3 id="Planning-with-LLM"><a href="#Planning-with-LLM" class="headerlink" title="Planning with LLM"></a>Planning with LLM</h3><p>基于自然语言输入生成行动规划后，它收集从规划执行中返回的错误信息。然后，这些信息被构建为重新提示，引导大语言模型纠正错误的行动。</p>
<p>然而，这样的优化过程发生在行动执行阶段之后。</p>
<h2 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h2><p>一个问题$ P$ 通常由一个元组$ P = ⟨S, A, T, s_{init}, G⟩$ 来表示。</p>
<p>对于离散状态集合$ S$ 中的每个状态$ s \in S$ ，可以从适用行动集合$ A(s) \subseteq A$ 中选择一个行动$ a \in A$ ，也就是说，行动$ a$ 的前提条件必须得到满足。</p>
<p>转移函数$ T : S \times A \to S$ 根据当前状态和所选行动来确定下一个状态。</p>
<p>$ s_{init} \in S$ 表示初始状态，$ G \subseteq S$ 是一组目标状态。</p>
<p>规划问题$ P$ 的一个解决方案是一个顺序行动规划$ \pi = (a<em>1, a_2, \ldots, a_n)$ ，它将初始状态$ s</em>{init}$ 控制到一个目标状态，即对于所有$ 0 \leq i \leq n$ ，都满足$ s<em>{i + 1} = T(s_i, a_i)$ ，并且$ s</em>{n + 1} \in G$ 。</p>
<p>对于长期顺序任务规划而言，行动的数量$ n$ 往往相对较大。专注于研究大语言模型（LLM）解决指定任务规划问题$ P$ 的能力。因此，我们主要关注的是规划的可行性和成功率，而非其最优性。</p>
<h3 id="PDDL"><a href="#PDDL" class="headerlink" title="PDDL"></a>PDDL</h3><p>规划领域定义语言（PDDL）</p>
<p>用PDDL语法表示的规划问题$ P$ 由两个文件组成：一个领域文件和一个问题文件。</p>
<p>领域文件体现了规划领域的基本规则。它不仅定义了用于阐明状态空间$ S$ 配置的谓词，还制定了所有可能行动$ a \in A$ 的前提条件和效果，即转移函数$ T$ 。</p>
<p>问题文件用于定义规划领域内可用的对象，以及初始状态和目标条件。</p>
<h2 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h2><p>利用迭代自我优化来找到准确性和可行性更高的行动方案。</p>
<p>该框架包含三个步骤：</p>
<ul>
<li><p>使用大语言模型（LLM）翻译器进行预处理</p>
</li>
<li><p>使用大语言模型规划器进行规划</p>
</li>
<li><p>借助从基于大语言模型的自我验证器或外部验证器中选择的验证器进行迭代自我优化循环</p>
</li>
</ul>
<h3 id="Preprocessing-with-LLM-Translator"><a href="#Preprocessing-with-LLM-Translator" class="headerlink" title="Preprocessing with LLM Translator"></a>Preprocessing with LLM Translator</h3><p>大语言模型（LLM）翻译器首先将给定的自然语言指令转换为规划领域定义语言（PDDL）格式</p>
<p>好处：</p>
<ul>
<li><p>使得可以使用现有的 PDDL 验证器作为外部验证器</p>
</li>
<li><p>使基于大语言模型的自我验证器不再仅仅依赖于语言线索，而是能够获得一种类似于对系统状态的状态机式的理解</p>
</li>
</ul>
<p>采用了一种被称为少样本上下文学习的技术</p>
<p>包括在提示中嵌入示例，有效地指导大语言模型如何以期望的方式对给定的查询做出回应</p>
<h3 id="Planning-with-LLM-Planner"><a href="#Planning-with-LLM-Planner" class="headerlink" title="Planning with LLM Planner"></a>Planning with LLM Planner</h3><p>大语言模型规划器将这些规划领域定义语言（PDDL）文件作为输入，并确定一个旨在完成给定任务的行动序列。</p>
<p>除了少样本上下文学习之外，我们还将思维链（CoT）技术整合到提供给大语言模型规划器的提示中。思维链技术通过将整体问题分解为中间步骤来发挥作用，从而使大语言模型能够处理那些可能无法通过标准提示方法解决的复杂推理问题。</p>
<p>在这一步中，得到了解决给定规划问题的初始行动方案。</p>
<h3 id="Iterative-Self-Refinement-Loop-with-Validator"><a href="#Iterative-Self-Refinement-Loop-with-Validator" class="headerlink" title="Iterative Self-Refinement Loop with Validator"></a>Iterative Self-Refinement Loop with Validator</h3><p>迭代自我优化循环的核心组件是验证器。</p>
<ol>
<li><p>通过对生成的行动序列进行检查，验证器生成反馈，找出任何被认为是错误的行动，然后将这些信息传达给大语言模型（LLM）规划器。</p>
</li>
<li><p>然后，基于这些反馈，大语言模型规划器启动一个自我优化过程，以纠正错误的行动并制定一个新的行动方案。</p>
</li>
</ol>
<p>自我优化过程在一个循环中迭代执行，在每一步中，验证器会在发现第一个错误时停止。然后返回与该错误相关的信息，确保每个迭代阶段都只专注于纠正这个检测到的错误 。</p>
<p>迭代优化循环会一直持续，直到验证器未发现任何错误，或者达到预先设定的最大迭代次数。通过迭代自我优化循环得出的行动序列，随后将被视为最终生成的行动序列。</p>
<p>两种类型的验证器：</p>
<ul>
<li><p>自我验证器，它利用大语言模型（LLM）来评估生成的行动规划的正确性</p>
<p>  将大语言模型用作内部自我验证器既节省时间又节省精力。然而，它存在着可能给出不准确甚至错误反馈的固有风险。因此，验证器类型的选择取决于具体的评估要求和验证场景的背景。</p>
</li>
<li><p>外部验证器，它借助外部工具来进行分析</p>
<p>  尽管外部验证器能够就生成的规划方案的可行性提供准确反馈，但其实现往往需要耗费大量精力，并且对于某些任务可能并不适用。</p>
</li>
</ul>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>在三个不同的规划领域开展了实验，不同的大语言模型对 ISR-LLM 性能的影响，以及大语言模型翻译器所起的作用。</p>
<h3 id="领域："><a href="#领域：" class="headerlink" title="领域："></a>领域：</h3><ul>
<li><p>烹饪</p>
</li>
<li><p>积木</p>
</li>
<li><p>移球</p>
</li>
</ul>
<h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><ol>
<li><p>LLM-direct：</p>
<p> 它利用大语言模型直接根据给定的 PDDL 输入制定行动方案。为了确保与 ISR-LLM 进行公平比较，在这种方法中，使用大语言模型翻译器将自然语言输入转换为 PDDL 文件。</p>
</li>
<li><p>ISR-LLM-self：</p>
<p> 它采用 ISR-LLM 框架，并使用基于大语言模型的自我验证器</p>
</li>
<li><p>ISR-LLM-external：</p>
<p> 它结合了一个外部验证器，为 ISR-LLM 生成反馈。为了减轻现有 PDDL 验证器的影响，并专注于分析 ISR-LLM 的性能，实现了自己定制的外部验证器</p>
</li>
</ol>
<h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p>在使用GPT3.5的情况下，与基准方法相比，所提出的ISR-LLM框架在所有规划领域的成功率都有显著提高。</p>
<p>基于大语言模型的自我验证器使性能提升了大约15%，而外部验证器则能进一步将成功率提高约40%到50%。唯一的例外是在烹饪领$n = 4$ 的情况下，观察到成功率提高了23%。这可能是因为在这个规划任务中所需的行动数量过多，使得大语言模型在纠正错误方面的效果不佳。 成功率也受到任务复杂度的影响，这由对象的数量体现。</p>
<p>在烹饪、积木世界和移球这三个领域中，对于所有三种方法</p>
<ul>
<li><p>LLM-direct：下降7%、10%、16%</p>
</li>
<li><p>ISR-LLM-self：下降14%、20%、23%</p>
</li>
<li><p>ISR-LLM-external：下降37%、17%、13%</p>
</li>
</ul>
<p>SR-LLM能够在这个领域中改善规划结果。</p>
<p>在长期顺序任务规划中，GPT4的表现大大优于GPT3.5，这证实了普遍认为GPT4具有明显更优越推理能力的观点。</p>
<p>基准方法，即LLM-direct，与GPT4结合使用时，在烹饪和移球领域能够实现超过90%的成功率，ISR-LLM在这些领域也保持了这一高性能水平。</p>
<p>当使用 GPT4 时，对象数量的影响似乎不那么明显</p>
<h3 id="相关结论"><a href="#相关结论" class="headerlink" title="相关结论"></a>相关结论</h3><h4 id="翻译器"><a href="#翻译器" class="headerlink" title="翻译器"></a>翻译器</h4><p>引入翻译后的 PDDL 文件可以使用现有的 PDDL 验证器，这有可能节省实现定制验证器所需的大量时间和精力</p>
<h4 id="行动落地"><a href="#行动落地" class="headerlink" title="行动落地"></a>行动落地</h4><p>当与合适的运动规划器配合使用时，所生成的行动方案可以直接转化为机器人可行的行动。</p>
<p>这凸显了在 ISR-LLM 框架中使用大语言模型翻译器的另一个优势，因为采用规划领域定义语言（PDDL）格式确保了所生成的每个行动都符合预定义的定义和结构。因此，这简化了运动规划器将行动方案转化为机器人可执行动作的任务</p>
<h1 id="论文精读"><a href="#论文精读" class="headerlink" title="论文精读"></a>论文精读</h1><h2 id="科学问题"><a href="#科学问题" class="headerlink" title="科学问题"></a>科学问题</h2><h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><p>受大语言模型（LLMs）在自然语言处理领域取得的重大成果启发，近期研究开始探索将大语言模型应用于机器人领域中复杂的长期顺序任务规划难题。大语言模型作为与任务无关的规划器，具有提升通用性的潜力，还能促进人类指令与规划系统之间的灵活交互。</p>
<h3 id="现有方法局限"><a href="#现有方法局限" class="headerlink" title="现有方法局限"></a>现有方法局限</h3><h4 id="使用基于搜索或基于采样的算法来找到可行的计划-1"><a href="#使用基于搜索或基于采样的算法来找到可行的计划-1" class="headerlink" title="使用基于搜索或基于采样的算法来找到可行的计划"></a><strong>使用基于搜索或基于采样的算法来找到可行的计划</strong></h4><p>然而，这些方法依赖于对规划领域预先确定的符号和逻辑表示，这通常需要高水平的专业知识来制定</p>
<h4 id="TAMP-1"><a href="#TAMP-1" class="headerlink" title="TAMP"></a><strong>TAMP</strong></h4><p>将离散空间中的高级任务规划和连续空间中的低级机器人运动规划结合成一个分层规划框架。在任务与运动规划中，关注点不仅限于单纯的任务规划，还包括所确定行动的可执行性</p>
<h4 id="Planning-with-LLM-1"><a href="#Planning-with-LLM-1" class="headerlink" title="Planning with LLM"></a><strong>Planning with LLM</strong></h4><p>基于自然语言输入生成行动规划后，它收集从规划执行中返回的错误信息。然后，这些信息被构建为重新提示，引导大语言模型纠正错误的行动。</p>
<p>然而，这样的优化过程发生在行动执行阶段之后。</p>
<h3 id="核心问题"><a href="#核心问题" class="headerlink" title="核心问题"></a>核心问题</h3><ol>
<li><p>如何在不额外大规模增加人工编写领域知识或依赖执行反馈的前提下，引入一种“迭代自我优化”机制</p>
</li>
<li><p>能否在生成行动方案的过程中，引入基于自我验证或外部验证的循环反馈体系，实现对错误行动的迅速定位、及时修正，并最终输出一个可行且准确的长序列行动规划？</p>
</li>
</ol>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><h3 id="Preprocessing-with-LLM-Translator-1"><a href="#Preprocessing-with-LLM-Translator-1" class="headerlink" title="Preprocessing with LLM Translator"></a><strong>Preprocessing with LLM Translator</strong></h3><p>大语言模型（LLM）翻译器首先将给定的自然语言指令转换为规划领域定义语言（PDDL）格式</p>
<p>好处：</p>
<ul>
<li><p>使得可以使用现有的 PDDL 验证器作为外部验证器</p>
</li>
<li><p>使基于大语言模型的自我验证器不再仅仅依赖于语言线索，而是能够获得一种类似于对系统状态的状态机式的理解</p>
</li>
</ul>
<h3 id="少样本上下文学习"><a href="#少样本上下文学习" class="headerlink" title="少样本上下文学习"></a>少样本上下文学习</h3><p>采用了一种被称为少样本上下文学习的技术</p>
<p>包括在提示中嵌入示例，有效地指导大语言模型如何以期望的方式对给定的查询做出回应</p>
<h3 id="Planning-with-LLM-Planner-1"><a href="#Planning-with-LLM-Planner-1" class="headerlink" title="Planning with LLM Planner"></a><strong>Planning with LLM Planner</strong></h3><p>大语言模型规划器将这些规划领域定义语言（PDDL）文件作为输入，并确定一个旨在完成给定任务的行动序列。</p>
<p>除了少样本上下文学习之外，我们还将思维链（CoT）技术整合到提供给大语言模型规划器的提示中。思维链技术通过将整体问题分解为中间步骤来发挥作用，从而使大语言模型能够处理那些可能无法通过标准提示方法解决的复杂推理问题。</p>
<h3 id="Iterative-Self-Refinement-Loop-with-Validator-1"><a href="#Iterative-Self-Refinement-Loop-with-Validator-1" class="headerlink" title="Iterative Self-Refinement Loop with Validator"></a><strong>Iterative Self-Refinement Loop with Validator</strong></h3><p>自动迭代优化过程：</p>
<ol>
<li><p>通过对生成的行动序列进行检查，验证器生成反馈，找出任何被认为是错误的行动，然后将这些信息传达给大语言模型（LLM）规划器。</p>
</li>
<li><p>然后，基于这些反馈，大语言模型规划器启动一个自我优化过程，以纠正错误的行动并制定一个新的行动方案。</p>
</li>
</ol>
<p>自我优化过程在一个循环中迭代执行，在每一步中，验证器会在发现第一个错误时停止。然后返回与该错误相关的信息，确保每个迭代阶段都只专注于纠正这个检测到的错误 。</p>
<p>迭代优化循环会一直持续，直到验证器未发现任何错误，或者达到预先设定的最大迭代次数。通过迭代自我优化循环得出的行动序列，随后将被视为最终生成的行动序列。</p>
<h3 id="两种类型的验证器"><a href="#两种类型的验证器" class="headerlink" title="两种类型的验证器"></a>两种类型的验证器</h3><ul>
<li><p>自我验证器</p>
<p>  它利用大语言模型（LLM）来评估生成的行动规划的正确性</p>
<p>  将大语言模型用作内部自我验证器既节省时间又节省精力。然而，它存在着可能给出不准确甚至错误反馈的固有风险。因此，验证器类型的选择取决于具体的评估要求和验证场景的背景。</p>
</li>
<li><p>外部验证器</p>
<p>  它借助外部工具来进行分析</p>
<p>  尽管外部验证器能够就生成的规划方案的可行性提供准确反馈，但其实现往往需要耗费大量精力，并且对于某些任务可能并不适用。</p>
</li>
</ul>
<h2 id="复现难度"><a href="#复现难度" class="headerlink" title="复现难度"></a>复现难度</h2><h3 id="数据集（公开）随机生成的情况"><a href="#数据集（公开）随机生成的情况" class="headerlink" title="数据集（公开）随机生成的情况"></a>数据集（公开）随机生成的情况</h3><p><a target="_blank" rel="noopener" href="https://github.com/ma-labo/ISR-LLM/tree/main/test_scenario">https://github.com/ma-labo/ISR-LLM/tree/main/test_scenario</a></p>
<h3 id="代码（公开）"><a href="#代码（公开）" class="headerlink" title="代码（公开）"></a>代码（公开）</h3><p><a target="_blank" rel="noopener" href="https://github.com/ma-labo/ISR-LLM">https://github.com/ma-labo/ISR-LLM</a></p>
<h3 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h3><p>一台配备英特尔（R）酷睿（TM）i7-10870H CPU（@2.20GHz 处理器，8 核）以及英伟达 RTX 3080 Max-Q GPU（16GB 显存）的笔记本电脑</p>
<p>算力要求一般</p>
<h3 id="可复现性评估（简单）"><a href="#可复现性评估（简单）" class="headerlink" title="可复现性评估（简单）"></a>可复现性评估（简单）</h3><p>全部公开</p>
<h3 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h3><p><img src="https://p.ipic.vip/ghtnre.png" alt="image-20250321102722649"><br><img src="https://p.ipic.vip/hgjjv7.png" alt="image-20250321102746200"></p>
<h2 id="LLM-amp-经典规划"><a href="#LLM-amp-经典规划" class="headerlink" title="LLM&amp;经典规划"></a>LLM&amp;经典规划</h2><p>1.采用LLM翻译自然语言为PDDL</p>
<p>2.PDDL作为输入，使LLM为规划器，</p>
<h2 id="技术路线"><a href="#技术路线" class="headerlink" title="技术路线"></a>技术路线</h2><p><strong>迭代优化</strong></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://arkham-three.vercel.app">Mengyang Cheng</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://arkham-three.vercel.app/2025/03/20/ISR-LLM/">https://arkham-three.vercel.app/2025/03/20/ISR-LLM/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-share"><div class="social-share" data-image="/img/butterfly-icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/03/20/Anticipate%20&amp;%20Actmore/" title="Anticipate &amp; Act : Integrating LLMs and Classical Planning for  Efficient Task Execution in Household Environments补充阅读"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">Anticipate & Act : Integrating LLMs and Classical Planning for  Efficient Task Execution in Household Environments补充阅读</div></div><div class="info-2"><div class="info-item-1">补充阅读LLM层输入输出如下： PDDL生成详细阅读论文和代码后并没有找到自动生成PDDL的部分，推测为手动生成 FD输入PDDL，输出PDDL，应该是终端生成，代码段没有找到调用痕迹 评估最后转换为json文件进行评估 </div></div></div></a><a class="pagination-related" href="/2025/03/21/LLM+P/" title="LLM+P: Empowering Large Language Models  with Optimal Planning Proficiency笔记"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">LLM+P: Empowering Large Language Models  with Optimal Planning Proficiency笔记</div></div><div class="info-2"><div class="info-item-1">论文梳理目的将经典规划器的优势融入大语言模型的框架  首先将自然语言描述转换为用规划领域定义语言（PDDL）编写的文件  然后利用经典规划器快速找到解决方案  最后再将找到的解决方案转换回自然语言   前置知识经典规划问题形式上，规划问题P的输入由一个元组⟨S, $ s^{\text{init}} $ ,$ s^{\text{G}} $ , A, f⟩来定义： S是一个有限且离散的状态集合，用于描述世界的状态（即状态空间）。我们假定状态空间是可分解的，这样对于每个状态s ∈ S，它都由一组固定变量的值来确定。 $ s^{\text{init}} $  ∈ S是世界的初始状态。 $ s^{\text{G}} $  ⊂ S是一组目标状态。目标状态集合$ s^{\text{G}} $ 通常被指定为一系列目标条件，在一个目标状态中，所有这些条件都必须成立。 A是一组符号化的动作。 f是底层的状态转移函数。f将当前状态和一个动作作为输入，并输出相应的下一个状态。 规划问题P的一个解是一个符号化的规划π，其形式为⟨a1, a2, …, aN⟩，使得a1的前置条件在$...</div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Mengyang Cheng</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">论文梳理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E7%9A%84"><span class="toc-number">1.1.</span> <span class="toc-text">目的</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Related-Work"><span class="toc-number">1.2.</span> <span class="toc-text">Related Work</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Long-Horizon-Sequential-Task-Planning"><span class="toc-number">1.2.1.</span> <span class="toc-text">Long-Horizon Sequential Task Planning</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%9F%BA%E4%BA%8E%E6%90%9C%E7%B4%A2%E6%88%96%E5%9F%BA%E4%BA%8E%E9%87%87%E6%A0%B7%E7%9A%84%E7%AE%97%E6%B3%95%E6%9D%A5%E6%89%BE%E5%88%B0%E5%8F%AF%E8%A1%8C%E7%9A%84%E8%AE%A1%E5%88%92"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">使用基于搜索或基于采样的算法来找到可行的计划</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#TAMP"><span class="toc-number">1.2.1.2.</span> <span class="toc-text">TAMP</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Planning-with-LLM"><span class="toc-number">1.2.2.</span> <span class="toc-text">Planning with LLM</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86"><span class="toc-number">1.3.</span> <span class="toc-text">预备知识</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#PDDL"><span class="toc-number">1.3.1.</span> <span class="toc-text">PDDL</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%A1%88"><span class="toc-number">1.4.</span> <span class="toc-text">方案</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Preprocessing-with-LLM-Translator"><span class="toc-number">1.4.1.</span> <span class="toc-text">Preprocessing with LLM Translator</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Planning-with-LLM-Planner"><span class="toc-number">1.4.2.</span> <span class="toc-text">Planning with LLM Planner</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Iterative-Self-Refinement-Loop-with-Validator"><span class="toc-number">1.4.3.</span> <span class="toc-text">Iterative Self-Refinement Loop with Validator</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-number">1.5.</span> <span class="toc-text">结果</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%86%E5%9F%9F%EF%BC%9A"><span class="toc-number">1.5.1.</span> <span class="toc-text">领域：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0"><span class="toc-number">1.5.2.</span> <span class="toc-text">评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%A7%E8%83%BD"><span class="toc-number">1.5.3.</span> <span class="toc-text">性能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E7%BB%93%E8%AE%BA"><span class="toc-number">1.5.4.</span> <span class="toc-text">相关结论</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BF%BB%E8%AF%91%E5%99%A8"><span class="toc-number">1.5.4.1.</span> <span class="toc-text">翻译器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A1%8C%E5%8A%A8%E8%90%BD%E5%9C%B0"><span class="toc-number">1.5.4.2.</span> <span class="toc-text">行动落地</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB"><span class="toc-number">2.</span> <span class="toc-text">论文精读</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A7%91%E5%AD%A6%E9%97%AE%E9%A2%98"><span class="toc-number">2.1.</span> <span class="toc-text">科学问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.1.1.</span> <span class="toc-text">背景介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%B0%E6%9C%89%E6%96%B9%E6%B3%95%E5%B1%80%E9%99%90"><span class="toc-number">2.1.2.</span> <span class="toc-text">现有方法局限</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%9F%BA%E4%BA%8E%E6%90%9C%E7%B4%A2%E6%88%96%E5%9F%BA%E4%BA%8E%E9%87%87%E6%A0%B7%E7%9A%84%E7%AE%97%E6%B3%95%E6%9D%A5%E6%89%BE%E5%88%B0%E5%8F%AF%E8%A1%8C%E7%9A%84%E8%AE%A1%E5%88%92-1"><span class="toc-number">2.1.2.1.</span> <span class="toc-text">使用基于搜索或基于采样的算法来找到可行的计划</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#TAMP-1"><span class="toc-number">2.1.2.2.</span> <span class="toc-text">TAMP</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Planning-with-LLM-1"><span class="toc-number">2.1.2.3.</span> <span class="toc-text">Planning with LLM</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98"><span class="toc-number">2.1.3.</span> <span class="toc-text">核心问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">2.2.</span> <span class="toc-text">解决方案</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Preprocessing-with-LLM-Translator-1"><span class="toc-number">2.2.1.</span> <span class="toc-text">Preprocessing with LLM Translator</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%91%E6%A0%B7%E6%9C%AC%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.2.2.</span> <span class="toc-text">少样本上下文学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Planning-with-LLM-Planner-1"><span class="toc-number">2.2.3.</span> <span class="toc-text">Planning with LLM Planner</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Iterative-Self-Refinement-Loop-with-Validator-1"><span class="toc-number">2.2.4.</span> <span class="toc-text">Iterative Self-Refinement Loop with Validator</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%A4%E7%A7%8D%E7%B1%BB%E5%9E%8B%E7%9A%84%E9%AA%8C%E8%AF%81%E5%99%A8"><span class="toc-number">2.2.5.</span> <span class="toc-text">两种类型的验证器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%8D%E7%8E%B0%E9%9A%BE%E5%BA%A6"><span class="toc-number">2.3.</span> <span class="toc-text">复现难度</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%88%E5%85%AC%E5%BC%80%EF%BC%89%E9%9A%8F%E6%9C%BA%E7%94%9F%E6%88%90%E7%9A%84%E6%83%85%E5%86%B5"><span class="toc-number">2.3.1.</span> <span class="toc-text">数据集（公开）随机生成的情况</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%EF%BC%88%E5%85%AC%E5%BC%80%EF%BC%89"><span class="toc-number">2.3.2.</span> <span class="toc-text">代码（公开）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83"><span class="toc-number">2.3.3.</span> <span class="toc-text">实验环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AF%E5%A4%8D%E7%8E%B0%E6%80%A7%E8%AF%84%E4%BC%B0%EF%BC%88%E7%AE%80%E5%8D%95%EF%BC%89"><span class="toc-number">2.3.4.</span> <span class="toc-text">可复现性评估（简单）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84"><span class="toc-number">2.3.5.</span> <span class="toc-text">整体结构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LLM-amp-%E7%BB%8F%E5%85%B8%E8%A7%84%E5%88%92"><span class="toc-number">2.4.</span> <span class="toc-text">LLM&amp;经典规划</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8A%80%E6%9C%AF%E8%B7%AF%E7%BA%BF"><span class="toc-number">2.5.</span> <span class="toc-text">技术路线</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/21/1/" title="Untitled">Untitled</a><time datetime="2025-03-21T15:24:58.398Z" title="Created 2025-03-21 23:24:58">2025-03-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/21/LLM+P/" title="LLM+P: Empowering Large Language Models  with Optimal Planning Proficiency笔记">LLM+P: Empowering Large Language Models  with Optimal Planning Proficiency笔记</a><time datetime="2025-03-21T12:21:29.055Z" title="Created 2025-03-21 20:21:29">2025-03-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/20/ISR-LLM/" title="ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning笔记">ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning笔记</a><time datetime="2025-03-20T08:59:01.021Z" title="Created 2025-03-20 16:59:01">2025-03-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/20/Anticipate%20&amp;%20Actmore/" title="Anticipate &amp; Act : Integrating LLMs and Classical Planning for  Efficient Task Execution in Household Environments补充阅读">Anticipate &amp; Act : Integrating LLMs and Classical Planning for  Efficient Task Execution in Household Environments补充阅读</a><time datetime="2025-03-20T08:40:55.351Z" title="Created 2025-03-20 16:40:55">2025-03-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/18/Large%20Language%20Models%20as%20Planning%20Domain%20Generators/" title="Large Language Models as Planning Domain Generators笔记">Large Language Models as Planning Domain Generators笔记</a><time datetime="2025-03-18T09:07:32.892Z" title="Created 2025-03-18 17:07:32">2025-03-18</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Mengyang Cheng</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>